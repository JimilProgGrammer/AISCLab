{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    t=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Network Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[0] # size of input layer\n",
    "    n_h = 4\n",
    "    n_y = Y.shape[0] # size of output layer\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the input layer is: n_x = 2\n",
      "The size of the hidden layer is: n_h = 4\n",
      "The size of the output layer is: n_y = 1\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0.9,0]]).T\n",
    "y = np.array([1])\n",
    "(n_x, n_h, n_y) = layer_sizes(X, y)\n",
    "print(\"The size of the input layer is: n_x = \" + str(n_x))\n",
    "print(\"The size of the hidden layer is: n_h = \" + str(n_h))\n",
    "print(\"The size of the output layer is: n_y = \" + str(n_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.00881318  0.01709573]\n",
      " [ 0.00050034 -0.00404677]\n",
      " [-0.0054536  -0.01546477]\n",
      " [ 0.00982367 -0.01101068]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "W2 = [[-0.01185047 -0.0020565   0.01486148  0.00236716]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propogation: Learn from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    Z1 = np.dot(W1,X) + b1\n",
    "    A1 = tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00793186]\n",
      " [ 0.0004503 ]\n",
      " [-0.00490824]\n",
      " [ 0.00884131]] [[ 0.0079317 ]\n",
      " [ 0.0004503 ]\n",
      " [-0.0049082 ]\n",
      " [ 0.00884108]] [[-0.00014694]] [[0.49996327]]\n"
     ]
    }
   ],
   "source": [
    "A2, cache = forward_propagation(X, parameters)\n",
    "print(cache['Z1'], cache['A1'], cache['Z2'], cache['A2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Cost of your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    if len(Y.shape)==2:\n",
    "        m = Y.shape[1] # number of example\n",
    "    else:\n",
    "        m = 1\n",
    "\n",
    "    logprobs = np.multiply(np.log(A2),Y) + np.multiply(np.log(1-A2),(1-Y))\n",
    "    cost = - (np.sum(logprobs)/m)\n",
    "    cost = float(np.squeeze(cost))  # makes sure cost is the dimension we expect. \n",
    "                                    # E.g., turns [[17]] into 17 \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 0.6932206508609429\n"
     ]
    }
   ],
   "source": [
    "print(\"cost = \" + str(compute_cost(A2, y, parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propogate the Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    \n",
    "    dZ2 = A2-Y\n",
    "    dW2 = (np.dot(dZ2,A1.T)/m)\n",
    "    db2 = (np.sum(dZ2, axis=1,keepdims=True)/m)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1-np.power(A1,2))\n",
    "    dW1 = (np.dot(dZ1, X.T)/m)\n",
    "    db1 = (np.sum(dZ1, axis=1,keepdims=True)/m)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW1 = [[ 0.00533277  0.        ]\n",
      " [ 0.00092549  0.        ]\n",
      " [-0.006688   -0.        ]\n",
      " [-0.00106522 -0.        ]]\n",
      "db1 = [[ 0.0059253 ]\n",
      " [ 0.00102832]\n",
      " [-0.00743111]\n",
      " [-0.00118358]]\n",
      "dW2 = [[-0.00396614 -0.00022517  0.00245428 -0.00442086]]\n",
      "db2 = [[-0.50003673]]\n"
     ]
    }
   ],
   "source": [
    "grads = backward_propagation(parameters, cache, X, y)\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Parameters using Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    \n",
    "    W1 = W1 - (learning_rate*dW1)\n",
    "    b1 = b1 - (learning_rate*db1)\n",
    "    W2 = W2 - (learning_rate*dW2)\n",
    "    b2 = b2 - (learning_rate*db2)\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[ 0.00241386  0.01709573]\n",
      " [-0.00061025 -0.00404677]\n",
      " [ 0.002572   -0.01546477]\n",
      " [ 0.01110194 -0.01101068]]\n",
      "b1 = [[-0.00711035]\n",
      " [-0.00123399]\n",
      " [ 0.00891733]\n",
      " [ 0.00142029]]\n",
      "W2 = [[-0.0070911  -0.0017863   0.01191635  0.0076722 ]]\n",
      "b2 = [[0.60004408]]\n"
     ]
    }
   ],
   "source": [
    "parameters = update_parameters(parameters, grads)\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    parameters = initialize_parameters(X.shape[0], n_h, Y.shape[0])\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations): \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693140\n",
      "W1 = [[ 0.01764973  0.0043651 ]\n",
      " [-0.00161198 -0.01863493]\n",
      " [-0.00986865 -0.00354759]\n",
      " [ 0.00394951 -0.00627001]]\n",
      "b1 = [[-0.00026284]\n",
      " [-0.00286328]\n",
      " [-0.00788308]\n",
      " [ 0.00530769]]\n",
      "W2 = [[ 0.00921951 -0.0042511  -0.01463653  0.00839942]]\n",
      "b2 = [[0.5999955]]\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X, y, 4, num_iterations=1, print_cost=True)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.where(A2 > 0.5, 1, 0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1]]\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(parameters, X)\n",
    "print(\"predictions = \" + str(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification on a sample Kaggle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"./datasets_4753_8110_ex2data1.csv\")\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.T\n",
    "X_test = X_test.values.T\n",
    "y_train = y_train.values.T\n",
    "y_test = y_test.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 90)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 90)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(1,y_train.shape[0])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(1,y_test.shape[0])\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692555\n",
      "Cost after iteration 1: 0.675788\n",
      "Cost after iteration 2: 0.709887\n",
      "Cost after iteration 3: 0.687753\n",
      "Cost after iteration 4: 0.682276\n",
      "Cost after iteration 5: 0.681284\n",
      "Cost after iteration 6: 0.681059\n",
      "Cost after iteration 7: 0.681012\n",
      "Cost after iteration 8: 0.681002\n",
      "Cost after iteration 9: 0.681000\n",
      "W1 = [[-0.15377971 -0.24994848]\n",
      " [ 0.18111922  0.149487  ]\n",
      " [-0.11658628 -0.11109082]\n",
      " [ 0.06943693  0.05971805]]\n",
      "b1 = [[-0.0058268 ]\n",
      " [ 0.00492081]\n",
      " [-0.00070213]\n",
      " [ 0.00040817]]\n",
      "W2 = [[ 0.04794049 -0.04228046 -0.17835274  0.03456175]]\n",
      "b2 = [[0.18993889]]\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X_train, y_train, 4, num_iterations=10, print_cost=True)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(parameters, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %d' % float((np.dot(y_test,predictions.T) + np.dot(1-y_test,1-predictions.T))/float(y_test.size)*100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
